Improvement and optimization methods in image generation



Wuxia Bai
2024.03.25



Chen M, Radford A, Child R, et al. Generative pretraining from pixels[C]//International conference on machine learning. PMLR, 2020: 1691-1703.


![img](./Markdown/Images/2024-03-25/img_1_1.png)


3


Methodology


![img](./Markdown/Images/2024-03-25/img_2_1.png)


Motivation:
Supervised pre-training: curating large labeled image datasets is both expensive and time consuming. 
Unsupervised pre-training:  learn general purpose representations from the much larger set of available unlabeled images and fine-tune them for classification


![img](./Markdown/Images/2024-03-25/img_2_2.png)


Architecture:


Context Reduction:
IRs: 32 × 32× 3, 48 ×48 × 3, or 64 ×64 × 3
motivated by early color display palettes, create 9-bit color palette by clustering (R, G, B) pixel values using k-means with k = 512.


4



Chen M, Radford A, Child R, et al. Generative pretraining from pixels[C]//International conference on machine learning. PMLR, 2020: 1691-1703.


Experiments and Results


![img](./Markdown/Images/2024-03-25/img_3_1.png)


![img](./Markdown/Images/2024-03-25/img_3_2.png)


5



Chen M, Radford A, Child R, et al. Generative pretraining from pixels[C]//International conference on machine learning. PMLR, 2020: 1691-1703.


Experiments and Results


![img](./Markdown/Images/2024-03-25/img_4_1.png)


![img](./Markdown/Images/2024-03-25/img_4_2.png)


![img](./Markdown/Images/2024-03-25/img_4_3.png)


![img](./Markdown/Images/2024-03-25/img_4_4.png)


6


Experiments and Results



Chen M, Radford A, Child R, et al. Generative pretraining from pixels[C]//International conference on machine learning. PMLR, 2020: 1691-1703.


![img](./Markdown/Images/2024-03-25/img_5_1.png)


![img](./Markdown/Images/2024-03-25/img_5_2.png)


![img](./Markdown/Images/2024-03-25/img_5_3.png)


![img](./Markdown/Images/2024-03-25/img_5_4.png)


7


![img](./Markdown/Images/2024-03-25/img_6_1.png)



Meng C, He Y, Song Y, et al. Sdedit: Guided image synthesis and editing with stochastic differential equations[J]. arXiv preprint arXiv:2108.01073, 2021.


![img](./Markdown/Images/2024-03-25/img_7_1.png)


8



Meng C, He Y, Song Y, et al. Sdedit: Guided image synthesis and editing with stochastic differential equations[J]. arXiv preprint arXiv:2108.01073, 2021.


Methodology


Motivation:
GAN-based methods: additional training data or loss functions for individual applications.
SDEdit:  does not require task-specific training or inversions


9


![img](./Markdown/Images/2024-03-25/img_8_1.png)


Methodology


![img](./Markdown/Images/2024-03-25/img_8_2.png)



Meng C, He Y, Song Y, et al. Sdedit: Guided image synthesis and editing with stochastic differential equations[J]. arXiv preprint arXiv:2108.01073, 2021.


10


Methodology


![img](./Markdown/Images/2024-03-25/img_9_1.png)



Meng C, He Y, Song Y, et al. Sdedit: Guided image synthesis and editing with stochastic differential equations[J]. arXiv preprint arXiv:2108.01073, 2021.


11


![img](./Markdown/Images/2024-03-25/img_10_1.png)



Meng C, He Y, Song Y, et al. Sdedit: Guided image synthesis and editing with stochastic differential equations[J]. arXiv preprint arXiv:2108.01073, 2021.


Methodology


![img](./Markdown/Images/2024-03-25/img_10_2.png)


12



Meng C, He Y, Song Y, et al. Sdedit: Guided image synthesis and editing with stochastic differential equations[J]. arXiv preprint arXiv:2108.01073, 2021.


Experiments and Results


![img](./Markdown/Images/2024-03-25/img_11_1.png)


13



Meng C, He Y, Song Y, et al. Sdedit: Guided image synthesis and editing with stochastic differential equations[J]. arXiv preprint arXiv:2108.01073, 2021.


![img](./Markdown/Images/2024-03-25/img_12_1.png)


Experiments and Results


14



Meng C, He Y, Song Y, et al. Sdedit: Guided image synthesis and editing with stochastic differential equations[J]. arXiv preprint arXiv:2108.01073, 2021.


![img](./Markdown/Images/2024-03-25/img_13_1.png)


Experiments and Results


15



Meng C, He Y, Song Y, et al. Sdedit: Guided image synthesis and editing with stochastic differential equations[J]. arXiv preprint arXiv:2108.01073, 2021.


![img](./Markdown/Images/2024-03-25/img_14_1.png)


Experiments and Results


16



Meng C, He Y, Song Y, et al. Sdedit: Guided image synthesis and editing with stochastic differential equations[J]. arXiv preprint arXiv:2108.01073, 2021.


![img](./Markdown/Images/2024-03-25/img_15_1.png)


Experiments and Results


![img](./Markdown/Images/2024-03-25/img_15_2.png)


![img](./Markdown/Images/2024-03-25/img_15_3.png)


17


![img](./Markdown/Images/2024-03-25/img_16_1.png)


18


![img](./Markdown/Images/2024-03-25/img_17_1.png)


Methodology


Karras T, Aittala M, Aila T, et al. Elucidating the design space of diffusion-based generative models[J]. Advances in Neural Information Processing Systems, 2022, 35: 26565-26577.


19


![img](./Markdown/Images/2024-03-25/img_18_1.png)


Experiments and Results


20


Advantages and disadvantages


1. Generative pretraining from pixels
Advantages: The first paper uses GPT pre-training method in image field
Disadvantages: The input is directly downsampled, and reshape is a bit simple and rough, losing a lot of information and the two-dimensional characteristics of the image

2. Sdedit: Guided image synthesis and editing with stochastic differential equations
Advantages: Without retraining, a single unconditional model can be used to solve problems such as conditional image generation, stroke based image composition and editing and other problems.
Disadvantages: It takes more time to generate a new image, as this iterative process takes much more time than a single pass through a more traditional GAN-based generation model.



